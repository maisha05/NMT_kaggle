{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_kaggle_V1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k0PbjMQbejHR"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import string\n",
        "from unicodedata import normalize\n",
        "from numpy import array\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install tensorflow_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIj4M3C6uGKy",
        "outputId": "3e731b04-35fa-45dc-bbd6-9aaec1dbe855"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.25.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.44.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (4.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (14.0.1)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(source_file, target_file):\n",
        "  source_sen = []\n",
        "  target_sen = []\n",
        "  with open(source_file,encoding=\"unicode_escape\") as file1, open(target_file,encoding=\"unicode_escape\") as file2:\n",
        "      for fl1, fl2 in zip(file1, file2):\n",
        "          fl1 = fl1.replace(\"\\n\", \" \")\n",
        "          fl1 = fl1.strip()        \n",
        "          fl2 = fl2.replace(\",\", \" \")\n",
        "          fl2 = fl2.replace(\"\\n\", \" \")\n",
        "          fl2 = fl2.strip()\n",
        "          source_sen.append(fl1)\n",
        "          target_sen.append(fl2)\n",
        "  return target_sen,source_sen"
      ],
      "metadata": {
        "id": "FT-aoyFp0c3z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_file = \"/content/sample_data/sentencesTrain.txt\"\n",
        "target_file = \"/content/sample_data/tokensTrain.txt\"\n",
        "targ, inp = load_data(source_file, target_file)\n"
      ],
      "metadata": {
        "id": "pULYb0oX0qve"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(inp)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "arP2t2uO1NQR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSONJZJy5WLy",
        "outputId": "3dcc987e-4439-4238-a7f5-ef48a3847fd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'When did you graduate high school?'\n",
            " b\"No, I'm going to Hawaii for spring break.\"\n",
            " b'If the horses play all day on the farm, by nighttime they will be exhausted.'\n",
            " b\"No, I wasn't old enough to vote at that time.\"\n",
            " b'Where did Sue move to?'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'IX-2p GRADUATE #HS WHEN GRADUATE WHEN'\n",
            " b'wave no IX-1p GO-OUT HANDSOME/ns-HAWAII_2+ FOR SPRING TAKE-BREAK SPRING TAKE-BREAK'\n",
            " b'#IF (2h)HORSE IX-loc:i PLAY+ ALL-DAY horse galloping ON FARM GUARANTEE NIGHT TIME+ EXHAUST (2h)HORSE PLAY+ ALL-DAY horse galloping ON GUARANTEE NIGHT TIME+ EXHAUST'\n",
            " b'#NO+ IX-1p NOT OLD ENOUGH TO/UNTIL VOTE THAT TIME part:indef ENOUGH TO/UNTIL VOTE TIME part:indef'\n",
            " b'fs-SUE IX-3p:i MOVE WHERE++ MOVE'], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tf.constant('¿Todavía está en casa?')"
      ],
      "metadata": {
        "id": "0VIcNmV-2SUM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_lower_v3(text):\n",
        "  text = tf.strings.join(['[Begin]', text, '[End]'], separator=' ')\n",
        "  return text"
      ],
      "metadata": {
        "id": "LbwA5he12XFZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_v3(example_text).numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXyOxobY2as6",
        "outputId": "d2525d58-5c99-4ae8-bffd-ea7365a2df9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Todavía está en casa?\n",
            "[Begin] ¿Todavía está en casa? [End]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_size = 6000\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_v3,\n",
        "    max_tokens=max_vocab_size)"
      ],
      "metadata": {
        "id": "50B72PVH2i2k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text_processor.adapt(inp)\n",
        "input_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2TaS26d2t8Q",
        "outputId": "a1fcd67a-d31c-4153-873d-7267f491cd36"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[End]', '[Begin]', 'the', 'I', 'to', 'If', 'a', 'is']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_v3,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvdxA9s52ybU",
        "outputId": "e6ac5021-dcc4-4991-dbe7-0b86908c1bf4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '[End]',\n",
              " '[Begin]',\n",
              " 'IX-1p',\n",
              " 'FRIEND',\n",
              " 'IX-3p:i',\n",
              " 'part:indef',\n",
              " 'IX-loc:i',\n",
              " '(1h)part:indef']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens[:3, :10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwZlySeE5FKC",
        "outputId": "7bc1dd99-8921-4c34-e374-b184b27c84f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10), dtype=int64, numpy=\n",
              "array([[  3,  23,  36,  13, 400, 182, 264,   2,   0,   0],\n",
              "       [  3,  25,  41,  52,   6, 794,  31, 526, 729,   2],\n",
              "       [  3,   7,   4, 386,  77,  48, 419,  30,   4, 681]])>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
        "tokens = input_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IJslBaj75Tti",
        "outputId": "bdd3f923-29a2-4b92-855a-e79c24f68343"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[Begin] When did you graduate high school? [End]          '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "units = 1024"
      ],
      "metadata": {
        "id": "7EI7qQCv84Kz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "    return output, state"
      ],
      "metadata": {
        "id": "gbPwegPN87Ec"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)"
      ],
      "metadata": {
        "id": "XmfGaa-b9DCD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "metadata": {
        "id": "ikgAMMkk9I1E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n"
      ],
      "metadata": {
        "id": "7A6CKJFO9TuM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "1iJh9zBgCBmM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = BahdanauAttention(units)"
      ],
      "metadata": {
        "id": "fiERxPA0CFws"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0))"
      ],
      "metadata": {
        "id": "x8UfLMgxCOkC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_slice = attention_weights[0, 0].numpy()\n",
        "attention_slice = attention_slice[attention_slice != 0]"
      ],
      "metadata": {
        "id": "t2Ip-smOCYUQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ],
      "metadata": {
        "id": "ccwqL86bCkzs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ],
      "metadata": {
        "id": "thLvNVNSCn3N"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "  if state is not None:\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "  logits = self.fc(attention_vector)\n",
        "  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ],
      "metadata": {
        "id": "edrkw9l-CrYo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Decoder.call = call"
      ],
      "metadata": {
        "id": "A7boraBpFY7X"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)"
      ],
      "metadata": {
        "id": "WKumwYloDzEG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "example_output_tokens = output_text_processor(example_target_batch)\n",
        "\n",
        "start_index = output_text_processor.get_vocabulary().index('[Begin]')\n",
        "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
      ],
      "metadata": {
        "id": "oJhQae6-D2cG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dec_result, dec_state = decoder(\n",
        "    inputs = DecoderInput(new_tokens=first_token,\n",
        "                          enc_output=example_enc_output,\n",
        "                          mask=(example_tokens != 0)),state = example_enc_state\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLDRJBjpD6Av",
        "outputId": "f4c50be3-d166-450a-8458-60d99b52c5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape: (batch_size, t, output_vocab_size) (64, 1, 1294)\n",
            "state shape: (batch_size, dec_units) (64, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)"
      ],
      "metadata": {
        "id": "TRqPHklpFgpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = np.array(output_text_processor.get_vocabulary())\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2RAaxrNFjML",
        "outputId": "fc21265e-8338-4d7f-8b81-67e396e94d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['REMEMBER+'],\n",
              "       ['RECENT-PAST'],\n",
              "       ['#CLUB'],\n",
              "       ['PIZZA_4'],\n",
              "       ['1p-INFORM:i']], dtype='<U33')"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec_result, dec_state = decoder(\n",
        "    DecoderInput(sampled_token,\n",
        "                 example_enc_output,\n",
        "                 mask=(example_tokens != 0)),\n",
        "    state=dec_state)"
      ],
      "metadata": {
        "id": "4Llfpzo8Fl3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQEPSUndFo5v",
        "outputId": "aaf611c1-dd73-4a5f-ab41-7c11ec003fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['HUNGRY/WISH'],\n",
              "       ['PEOPLE'],\n",
              "       ['TWO'],\n",
              "       ['ARRIVE'],\n",
              "       ['(1h)SECOND-IN-LIST']], dtype='<U33')"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss)"
      ],
      "metadata": {
        "id": "3eOOBHrPFtKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ],
      "metadata": {
        "id": "znUEh_LjFxw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _preprocess(self, input_text, target_text):\n",
        "  self.shape_checker(input_text, ('batch',))\n",
        "  self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  input_mask = input_tokens != 0\n",
        "  self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask"
      ],
      "metadata": {
        "id": "ks0IiS3SF6i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTranslator._preprocess = _preprocess"
      ],
      "metadata": {
        "id": "WxTvcCm_F97a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs  \n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  variables = self.trainable_variables \n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "\n",
        "  return {'batch_loss': average_loss}"
      ],
      "metadata": {
        "id": "TkciVkJ2GB0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTranslator._train_step = _train_step"
      ],
      "metadata": {
        "id": "TmeTP4HmGEdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ],
      "metadata": {
        "id": "J9dWxXkIGIY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTranslator._loop_step = _loop_step"
      ],
      "metadata": {
        "id": "hE9e7Wk3GLWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "\n",
        "\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "metadata": {
        "id": "HxlsT4ATGPYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.log(output_text_processor.vocabulary_size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5l2Ag2OGS24",
        "outputId": "b3f1e940-c1ea-497f-ad36-c2427eee3609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.165493475060845"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ],
      "metadata": {
        "id": "PD94ek95IBdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTranslator._tf_train_step = _tf_train_step"
      ],
      "metadata": {
        "id": "ek5Ty4a0IENU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator.use_tf_function = True"
      ],
      "metadata": {
        "id": "yPOc7W0wIHX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator.train_step([example_input_batch, example_target_batch])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrKoNK0vIKb2",
        "outputId": "1016186d-2e08-442f-9288-cb69f6b03a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.6397886>}"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfdE9Wp1IfMC",
        "outputId": "ccaae569-c84d-4d6d-a52a-962c4a82abae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.609764>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.556749>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.4090767>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.8593884>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.921364>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.194613>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.4171195>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.395831>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.2086835>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.9818525>}\n",
            "\n",
            "CPU times: user 2min 45s, sys: 1.68 s, total: 2min 47s\n",
            "Wall time: 1min 32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for n in range(100):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([example_input_batch, example_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_7eSeADqI9wT",
        "outputId": "2aba3676-7cea-4a66-fabc-cff858ae6812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "....................................................................................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcbf1371350>]"
            ]
          },
          "metadata": {},
          "execution_count": 167
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor)\n",
        "\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "metadata": {
        "id": "4xE-U4jVMZGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ],
      "metadata": {
        "id": "Qz86cxY4McrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_translator.fit(dataset, epochs=30,\n",
        "                     callbacks=[batch_loss])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o96aJKnhMfvF",
        "outputId": "22f2fdf9-6d35-49f0-fce5-ce1b30ba05f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "11/11 [==============================] - 103s 9s/step - batch_loss: 3.5706\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 106s 10s/step - batch_loss: 3.2433\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 105s 10s/step - batch_loss: 2.9512\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 102s 9s/step - batch_loss: 2.6553\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 103s 9s/step - batch_loss: 2.3423\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 108s 10s/step - batch_loss: 2.1134\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 108s 10s/step - batch_loss: 1.8711\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 110s 10s/step - batch_loss: 1.6297\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 106s 9s/step - batch_loss: 1.4236\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 101s 9s/step - batch_loss: 1.2329\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 108s 10s/step - batch_loss: 1.0674\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 108s 10s/step - batch_loss: 0.9115\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 109s 10s/step - batch_loss: 0.7840\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 108s 10s/step - batch_loss: 0.6589\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 105s 10s/step - batch_loss: 0.5518\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 107s 10s/step - batch_loss: 0.4654\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 107s 10s/step - batch_loss: 0.3800\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 109s 10s/step - batch_loss: 0.3074\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 107s 9s/step - batch_loss: 0.2512\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 107s 10s/step - batch_loss: 0.2068\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 108s 10s/step - batch_loss: 0.1718\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 109s 10s/step - batch_loss: 0.1418\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 106s 10s/step - batch_loss: 0.1213\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 105s 10s/step - batch_loss: 0.1045\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 107s 10s/step - batch_loss: 0.0915\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 111s 10s/step - batch_loss: 0.0800\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 111s 10s/step - batch_loss: 0.0706\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 105s 10s/step - batch_loss: 0.0636\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 110s 10s/step - batch_loss: 0.0570\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 104s 9s/step - batch_loss: 0.0518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcbed271a90>"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Bd5VsvajfplB",
        "outputId": "97124075-f1df-4772-8f21-2a6f29980695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CE/token')"
            ]
          },
          "metadata": {},
          "execution_count": 172
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxcVZ338c+v1t67s++QACEhLAlJRDaRXeBBcRQUdAZHUZwZ8IEZdRR8BpdRRx2FYQZmlBEUHBwQ0AERxIAIwsjSCSEbJASSkH3vfamu7vP8cW9VV3VVd5qkb3V11/f9etWLuktVn7p0+lvnnHvOMeccIiJSukLDXQARERleCgIRkRKnIBARKXEKAhGREqcgEBEpcQoCEZESF1gQmFmZmb1kZq+a2Woz+3qec+Jmdr+ZrTezF81sZlDlERGR/IKsEXQCZzvn5gMLgAvM7OQ+51wF7HfOHQXcAnw3wPKIiEgegQWB87T4m1H/0Xf02iXA3f7zB4FzzMyCKpOIiOSKBPnmZhYGlgJHAbc7517sc8o0YDOAcy5pZo3AOGBPn/e5GrgaoLKyctHcuXODLLYcgh7nWL2tiSm1ZYyvigPQnuhm/e6W9DnRcIi5k6uHq4giJWnp0qV7nHMT8h0LNAicc93AAjOrA35lZsc551YdxPvcAdwBsHjxYldfXz/EJZWh0pnsZs7/+y1ffN8crjnrKABeeGsvl9/xQvqcSTVxXrzx3OEqokhJMrNN/R0ryF1DzrkG4Gnggj6HtgIzAMwsAtQCewtRJglGNOT9SiWSPel9HV3dWed092h+K5FiEuRdQxP8mgBmVg6cB7ze57RHgE/4zy8Ffu80C96IFgoZ0bDR1Z0ZBD1Z5yQVBCJFJcimoSnA3X4/QQj4hXPuUTP7BlDvnHsEuBP4mZmtB/YBlwdYHimQaDiUFQSdyd4agRl0dysIRIpJYEHgnFsBnJhn/00ZzzuAy4IqgwyPaDjUb9PQuMo4rZ3J4SiWiPRDI4tlyMUiIRL+t/7bn17Psk0N6WNT68rURyBSZAK9a0hKU8xvGmps7+Kfn1ib3n/nJxbzytsNrNraOIylE5G+VCOQIRcNG4lkD2/vbcvaf+aciUTCRo+DHtUKRIqGgkCGXCQc4pFXt7Gyzzf/cMiIhLyB4926OUykaCgIZMit3+WNIv7eE33vFoawP85A/QQixUNBIEPuKxcdA0BDWxfjKmNZx1I1Ao0lECke6iyWIfeZM47goWVbeH1HM4ePq+DWy0/kjV3NgNc8BBpLIFJMVCOQQEytKwfguGm1nD57PJ88bRYAkXCqRtDT72tFpLAUBBKI1Mji46bVZu1P1wjUNCRSNBQEEogJ/hTUR0/Knm66vz6Cfa2JwhRMRHIoCCQQX33/sXz/svnMn963RpB719DvX9/Jwn9cwotvaeJZkeGgIJBA1FZEuXTRdPouOJevRvCbFTsA+OgdL/DJn7xEW0JzEYkUkoJACqq3j6C3s3h7Y3v6+dNrd/P067sLXi6RUqYgkIJKBUHmRHTbGzuyzmnvs5CNiARLQSAFlQqCv39oBbubOwHY0ScIMqewFpHgKQikoFJ9BACtnUl6elxODSCRVI1ApJAUBFJQ4YwgaEt005nn23+iWzUCkUJSEEhBRUK9v3Itncm8/QFqGhIpLAWBFFRmjaC5o0tBIFIEFARSUKm5hgBuXrKOtTuaso7HIiE61TQkUlAKAimozBrB6m1NfOqn9QB878Mn8Ph17yHWZ+F7EQmegkAKKvOuoUxT6so4ZkqNt/C9gkCkoBQEUlDhfoKgPBoGUI1AZBgoCKSgMu8aylSWCoJISLePihSYgkAKqr8FacpjGUGgGoFIQSkIpKDaEvlHDatpSGT4KAikoOZOrmZSTTxnf7mahkSGTWBBYGYzzOxpM1tjZqvN7Lo855xpZo1mttx/3BRUeaQ4VJdFefHGc7n18gXEI72/fplNQ/mmnRCR4EQCfO8k8Hnn3DIzqwaWmtkS59yaPuf90Tl3cYDlkCJ0yYJprNnexI+eeQsgHQrxSIjmjtyFaVJrIEfDqsSKDLXA/lU557Y755b5z5uB14BpQf08GXlqyqIAhIz0Smb99RH82b8/z+yvPM7aHc0FLaNIKSjI1yszmwmcCLyY5/ApZvaqmT1uZscWojxSHGrKvApp5jr2/fURrNrqTUXx6uaGnGMicmgCDwIzqwIeAq53zjX1ObwMONw5Nx/4N+B/+nmPq82s3szqd+/WMoajxfiq3E7j/m4fjflNQtsylrUUkaERaBCYWRQvBO51zv2y73HnXJNzrsV//hgQNbPxec67wzm32Dm3eMKECUEWWQronGMm8dHFM7j8XTPS+/prGnJ41YZtDQoCkaEWWGexeY2+dwKvOedu7uecycBO55wzs5PwgmlvUGWS4hKLhPjupSfk7OvbNNTT4+jq9oKg7/rGInLogrxr6DTgL4CVZrbc33cjcBiAc+6HwKXAX5tZEmgHLnfOuXxvJqUhX9NQZjCoRiAy9AILAufcc0D+GcZ6z7kNuC2oMsjIky8IujKCQDUCkaGnm7KlqMTDXtNQZsUwFQwTquO0JbqzgkFEDp2CQIpKzB9YlmoOOv+WZ/jZC5uA3ttNO/IsbykiBy/IPgKRdyw1HXVnsoeQGet2trBu5xsA1JZ7A9Dau7qp9gejicihUxBIUUkFwZptTfzomTezjqWCoCOhpiGRoaQgkKKSCoLP3F1Pc2f2nEM1GTUCERk66iOQopKajrpvCEBGjUBBIDKkFARSVMqi/f9KpiapU41AZGgpCKSopGoE+dSUey2ZCgKRoaUgkKJSFus/CFJNQ50KApEhpSCQolIWOXAQ9K0RdHR18/0n1tKWyO1XEJEDUxBIUSkfoEaQ7iPoc/voA/Wbue3p9fz702/me5mIHICCQIrKgJ3FB7hraF9bIpAyiYx2CgIpKgN1FvfXNFQe8zuRE+o7EDkYCgIpKmUDBEFVPIJZbo0gNT9Ra56xByJyYAoCKSrxSP+/krFIiLJIOCsImjq62LyvDdBtpSIHS1NMSFHxFrbLLxYJUR4LZ/3Bf/e3nkpvt6lpSOSgqEYgI0YkZJRHw+m7hnY2dWSFgoJA5OAoCGTEMDPi0RAdSe8P/ksb9mUdb9c4ApGDoiCQohXK00pUEQvT5ncKN7R3ZR3buLeNpZv25b5IRAakIJCiVf//zuOFG87hqIlV6X3V8SgtfhA09QkCgH958o2ClU9ktFBnsRSdsmiI8miYsZUxAB6+5jSaO7w//tVlETbt9e4SauwTBLFwiPgAU1Rs3tfG9DHlA3ZIi5QiBYEUnVe/en7WdmU8QmXc+1WtKY/S3OEFQGNbdhAcM7Wm34Xt6zfu49If/onvXXoCH1k8I4BSi4xcCgIpOgN9q68ui6RrBw3t2VNKxMJGIpk/CF7a6PUdrN/VMkSlFBk91EcgI0p1WZTmziTdPS6naSgaDvVbI9jV1AnAxOp44GUUGWkUBDKi1JR5ldiWziSN7Uli4d5f4YGCYGdTB+DVKEQkm4JARpTUVNTNHV00tXcxqbb3G34sEiLR7fK+blezVyPo6ue4SClTEMiIkvpG39SepLG9i8k1ZeljsUHUCJL9HBcpZQoCGVFSaxLsa03Q0plkUkYQRAfoLN7f6nUsq0YgkiuwIDCzGWb2tJmtMbPVZnZdnnPMzP7VzNab2QozWxhUeWR0SNUIXnl7PwDHTq1NHxuoj6DVn4eoq0c1ApG+guw5SwKfd84tM7NqYKmZLXHOrck450Jgtv94N/Af/n9F8qr2+wh+sGQdAIsOH5M+Fo3kD4LMaau7kqoRiPQVWI3AObfdObfMf94MvAZM63PaJcA9zvMCUGdmU4Iqk4x808eUc9KssentY6ZUp5/HwqG8TUOZU1EkVSMQyVGQPgIzmwmcCLzY59A0YHPG9hZywwIzu9rM6s2sfvfu3UEVU0aAaDjELz57CpNq4hw5oZLKWG+lNhYJ5e0DyBxvkFBnsUiOwG+qNrMq4CHgeudc08G8h3PuDuAOgMWLF6tuLzzzxbNwDkIZU5RGw5a3aSgzCJLqLBbJEWgQmFkULwTudc79Ms8pW4HMiV+m+/tEBtR3beMPLphKNBwi2ePo6XFZAZEZBP11JouUsiDvGjLgTuA159zN/Zz2CHClf/fQyUCjc257UGWS0emtb1/ELR9dQNQfZdy3+Sc7CFQjEOkryBrBacBfACvNbLm/70bgMADn3A+Bx4CLgPVAG/DJAMsjo1Tq239quomu7p6sGkMqCCpiYdUIRPIILAicc88BA0787pxzwDVBlUFKSyySCoLsb/2pIBhbGdPIYpE8NLJYRo1oRo0gU2N7F9XxCPF+7ioSKXUKAhk1omGvApo5luCxldtZvbWJmvLogCOPRUqZ5uSVUSPVNJTqLN7XmuBv7l0GwLwpNYRD+W8vFSl1qhHIqNG3aej59XvSx2rLo0TDRrJHTUMifalGIKNGKghWbW0iZJYTBPvaXL+zk4qUMgWBjBqppqEvPPAqAHMm9c5DVFsepaUzSXvGBHQi4lHTkIwaqc7ilDd2Naef11ZEifQzBYVIqVMQyKiRuX4xQI+DqbXewjW16buG1Ecg0peCQEaNaDj313nOZK95qDwa7ndSOpFSpyCQUSNfEIypiAHQ45w3KZ2CQCSHgkBGjVgkd0aT1BrHyR5HJKSmIZF8Bh0EZnaqmX3MzK5MPYIsmMg7lbmQPUA4ZPz5yYdRFY/wf46fQiyipiGRfAZ1+6iZ/Qw4ElgOpO6/c8A9AZVL5B1LrWecEjI4amI1q77+PgC/RqAgEOlrsOMIFgPz/NlCRUaEkGU3FXl9BPoVFulrsE1Dq4DJQRZEZCjc9rET089zg8Bo7+om3/eZm5esY+aXfxN4+USK0WCDYDywxsyeMLNHUo8gCyZyMC4+YSr/eeViwGsayhTx5xq69uev5LzuX596A0BTUEhJGmzT0NeCLITIUKqMeauThfokwZu7WgH4zcrt3N7Pa1s7k8QisSCLJ1J0BlUjcM49A2wEov7zl4FlAZZL5KCV+0EQ7hMEn37PLACOmFCZtT+zqailMxlw6USKz6CCwMw+AzwI/MjfNQ34n6AKJXIoKmJeRbdvH8HimWO5bNF02hPejW/dPY5VWxv5xE9eTp+jIJBSNNimoWuAk4AXAZxzb5jZxMBKJXIIKlJNQ5Y7wKy6LEpzh/fH/rn1e/jEXS9lHVcQSCkabGdxp3MukdowswjeOAKRopNqEsoz4wQ15RFaOpN09zh2N3cCMK2unFsvXwAoCKQ0DbZG8IyZ3QiUm9l5wN8Avw6uWCIHb3JNGVecdBh/fvJhOcdq/EFnLR1JWjq6APj1505nb0tner9IqRlsEHwZuApYCXwWeMw595+BlUrkEIRCxj996Pi8x6rLvF/5po6udBNRVTxCh79gTatqBFKCBts09DXn3H865y5zzl0K3GVm9wZZMJEgpCahu+BfnmVrQzvxSIhYJESVHxBqGpJSNNggmGFmNwCYWQx4CHgjsFKJBCRVI2hNdHPfy5vT8xNVxhQEUroGGwSfAo73w+BR4Bnn3NcCK5VIQGr6TExX4wdDOGRUxMLqI5CSNGAfgZktzNi8FW8cwfN4nccLnXMaVCYjSmU8+1c+VUNIHWtNKAik9Byos/gHfbb3A/P8/Q44u78XmtldwMXALufccXmOnwk8DGzwd/3SOfeNwRVb5OBMrSvjhOm1VJdFeH793qzRx1XxSLoDua87nn2TIydUcc4xkwpVVJGCGTAInHNnHcJ7/xS4jYHXLPijc+7iQ/gZIu9IPBLmkWtP5+HlW3l+/d6sP/xV8Ujeu4ZaOpP88xNred+xkxUEMioNdoqJWjO72czq/ccPzKx2oNc4554F9g1JKUWG2NS6coCsIKiMh/N2Fj+/fg9d3U5rGcioNdjO4ruAZuAj/qMJ+MkQ/PxTzOxVM3vczI7t7yQzuzoVQrt37x6CHyulLhUETf6gMoCqeJSWzu6cc/+w1vud0+pmMloNdkDZkc65D2dsf93Mlh/iz14GHO6cazGzi/AmsZud70Tn3B3AHQCLFy/W1zI5ZJOq4wB8YP7U9L6qeDinacg5xzNrdwGQUBDIKDXYIGg3s9Odc88BmNlpQPuh/GDnXFPG88fM7N/NbLxzbs+hvK/IYETCIZbfdB5VGXcRVZVFcpqG3tzdwrbGDkA1Ahm9BhsEfwXck9EvsB/4xKH8YDObDOx0zjkzOwmvmWrvobynyDtRV5G9AE1lPDcIVm5tBGBidZwu9RHIKDXYIGhyzs03sxrwvs2b2ayBXmBm/w2cCYw3sy3AV4Go//ofApcCf21mSbzaxeUu32KyIgVSFYuQSPaQSPYQi3jdZ+t2thANG0dPqs7qTxAZTQYbBA8BCzObc/AWqlnU3wucc1cM9IbOudvwbi8VKQqp+YYyl6t8Y2cLs8ZXUh4Ls8efoVRktDnQyOK5wLFArZl9KONQDVAWZMFECi016rilM8mYSj8IdjVz3FSvRTTZowqrjE4HqhHMwRsdXAe8P2N/M/CZoAolMhyqM4Ig2d3Db1fvYNPeNi5/12Gs3dGkzmIZtQ4UBBXAF4A7nHN/KkB5RIZNqkbw9Npd1G/cxz88vBqAc46ZyFu7W+hKKghkdDpQEBwGPABEzewp4HHgJXXqymiU6iP43m/XcsJ0rzloSm0ZsydWEY2ESOiuIRmlBhxZ7Jz7rnPubOAi4FW86aiXmdnPzexKM9PEKzJqpBa9B1ixpZEPL5zOE397BmZGLByiq7uHnU0d6bWORUaLQU0x4Zxrds79yjn3WefcicA3gQkMPKGcyIgyfUwFE/wRxwAfPHFqev2CSMjo6u7h3Juf4V3fehJVimU0GTAIzOzPM56flnrunFsDdDrn3hdg2UQKqioe4eWvnJvePvXI8enn0YhXI0hNUvfCW73zKXZ0dfOPj66hoS1RuMKKDKED1Qj+LuP5v/U59qkhLotIUVjyt2fw+HXvyVqrIBoO0dXtGF/l1RiWvb0/fey/XtjEnc9t4CfPbyx0UUWGxIE6i62f5/m2RUaF2ZOqc/bFwt6ve7LHu3NoV1NH+tgbO1sAGFcVy3mdyEhwoBqB6+d5vm2RUSsa9v6pNLR500zsbOrkZy9sYv2uZjbubQUgFh7srO4ixeVANYK5ZrYC79v/kf5z/O0jAi2ZSBGJ9vkjv72pg3/4n1XEwiHGVHodyh1duWsZiIwEBwqC+cAkYHOf/TOAHYGUSKQIRSPZQbBxj1cLSHT3sLPJu520QwPOZIQ6UF32FqDRObcp8wE0+sdESkKqjwCgMhamsT13JlLVCGSkOlAQTHLOrey70983M5ASiRShSKj3n8rM8ZV5z+noUo1ARqYDBUHdAMfKh7IgIsUss2nosLEVWccm15RRHY/QmVSNQEamAwVBvZnlzDJqZp8GlgZTJJHik9k0lFr4PmX+jFri0XC/NYIVWxo0ElmK2oGC4Hrgk2b2BzP7gf94BrgKuC744okUh8y7hqbUZi/FccL0OsqiITrz9BEsWbOTD9z2PL9ctjXwMoocrANNOrfTOXcq8HVgo//4unPuFOec7hqSkpEZBH1rBCceVkdZNExHnqaht3Z7g83WbG/KOSZSLAa1VKVz7mng6YDLIlK0+qsRfO/SEzjliHGURUN5m4ZS01QktaiNFDENhRQZhFikt49gckYQXHjcZMyMskg47+2jTf4kdQkFgRQxBYHIIGTWCKrivRXpypj3vCzaGwTOOb7yq5Us3bSfvf6C93taNDOpFK9BNQ2JlLqQ9dYIMoMg5Df9lEVDbNrXSVsiye7mTu598W3KomH2+gGQOUmdSLFRjUBkEFLNQd/+s+Mxy514Nx4Ns3lfO+ff8iwrtjQCsHV/O3tbvRpBahoKkWKkGoHIIIyvivPmty/KWqMgU9wfcLZlfzurtvpB0NBOS6fXR5AKBJFipCAQGaTMELjunNls2d+e3t7f2tsHsDIjCLr8TuKubkci2UMsokq4FB8FgchB+Nvzjs7a3tbQ2wewamsjIYN9fjiMrYyxrzVBe6JbQSBFSb+VIkMgs+mnqSPJSbPGprdnjPEGoLV1JQteLpHBCCwIzOwuM9tlZqv6OW5m9q9mtt7MVpjZwqDKIhK0H/3FoqztC4+bkn4+w5+krrUzd5zB8s0N3P2/GwMtm8iBBFkj+ClwwQDHLwRm+4+rgf8IsCwigVp0+Fi++L456e3TZ49PP08FQXsiNwg+ePvzfPWR1cEXUGQAgQWBc+5ZYN8Ap1wC3OM8LwB1ZjZlgPNFilrm+IKZ4yqJ+J3LqWmrWxP9Nw1pURsZTsPZRzCN7CUwt/j7cpjZ1WZWb2b1u3fvLkjhRN6pVBCEQ0Y4ZEyp88YeHDZAjSBlf5tGHsvwGRGdxc65O5xzi51ziydMmDDcxRHJq6rMC4LyaBiAaXXllEVDjK+KA7k1gsw1Cva35i59KVIowxkEW4EZGdvT/X0iI1K1XyMoj3lBcMyUGmaNr6LC397W0M5vV21Pn9/c2RsMDaoRyDAaznEEjwDXmtl9wLuBRufc9gO8RqRo9a0RfOmCuSS6e+hKeoPKvv3Y6wAsv+k86ipibM8Ye9DQrhqBDJ/AgsDM/hs4ExhvZluArwJRAOfcD4HHgIuA9UAb8MmgyiJSCKmJ6VI1gLJoOGtW0pQ9LQnqKmJs2d+W3qc+AhlOgQWBc+6KAxx3wDVB/XyRQjt8XAXRsGXdRgq98xClXHnni9z+8YW8vqM5va+hTTUCGT6aYkJkiFSXRXnjWxfl7O87W+m2xg4+c089px45nml15exrTWTNVSRSaCPiriGR0aY90c3LG/cxZ3I1Yyqi6iOQYaUgEBkGrYlutjd2cMoR46itiOmuIRlWCgKRArjtYydy39UnZ+1779ETuOr0WYypiLJffQQyjBQEIgVw8QlTOfmIcVn7zjlmIqGQMaYilnPX0KMrtrGtoR2RQlAQiAyDU48cxyULvBlV6iqiWXcNtSe6ufbnr3Dqd37PkjU7h6uIUkJ015BIAd39qZNwznHmnInpfV4QJOjpcYRCxo6Mhe4/c089AA/+1Sksnjk25/1EhoKCQKSA3nt07lxZYypi9Dh4YOlmJtaUURYJ55zzuzU7FQQSGAWByDCrq4gB8KWHVgJwy0fn55xTGdM/VQmO+ghEhtmYimjWdub6xynxqP6pSnD02yUyzOr6BMGyTftzzmnrTOKco6u7p1DFkhKiIBAZZkdPquY9s8fz5ycfBsDTa3flnNPcmeSHz7zF7K88TlOHxhzI0FLDo8gwqy6L8rOr3k1jexf3vvg2PS73nOaOJI+t3ABAQ2sXNWXR3JNEDpJqBCJForY8yrhKr+P4r888kvcePYFZ4ysBaOlIppe67EhqfWMZWgoCkSJy7NRaAM6fN4m7P3UST3/hTBYdPobmzi46/AVuWjNWNrv96fWc+k9PDUtZZfRQ05BIEfn+ZfP51StbmD+9Lr2vKh6hoS1Bwg+CtkQ3ye4ezr35GTbubevvrUQGTTUCkSIyoTrO1WccSSjUu4ZBdVmE5o7eWkBLZ5LfrdmZFQK6m0gOhYJApMhVl0WyFrpvSyR5fNWOrHPaEuo3kIOnIBApctVlUXY3d6a3Wzq7eXtfdpNQe54geHVzA794eXPg5ZORT0EgUuSOm1abtd3WmWTr/j5B0JUbBD9+bgNf+/XqQMsmo4OCQKTIve/YSVnbe1o62dOSvX5BWyJJXxv2tNCW6M5bWxDJpCAQKXLxSJinv3AmL914DlXxCOt2tgAwY2x5+pyOPjUC5xwb93i1hr2tnYgMREEgMgLMGl/JxJoyKmJhVm1tBOAL589JH+/bWbynJUGL38G8t0XrIcvAFAQiI0hFLMze1gQTq+OcN28Sj37udCA3CDbubU0/39eqIJCBKQhERpDU2IEvXziXiliEipi3iE3fpqENu3uDYE+LmoZkYBpZLDICXXT8FAAq/AVrUjWCzmQ3v1mxnftefpuQQY+DvaoRyAEoCERGkLv+cjFtiW7Kol5NoNz/b3uim4a2BF94YAVPvuYteD9zXAU7mjrYqxqBHECgTUNmdoGZrTWz9Wb25TzH/9LMdpvZcv/x6SDLIzLSnT13EhefMDW9Xe43DX3j0TUs+MYSnnxtJ8f74w6aO5LMGFPBqq1Nw1JWGTkCCwIzCwO3AxcC84ArzGxenlPvd84t8B8/Dqo8IqNRNNw7J9H58ybxwF+dws+uOgmAOZOref/8qfzprb1s3qfJ6aR/QdYITgLWO+fecs4lgPuASwL8eSIlx6w3CL72gWN518yx1FXEePCvTuG2jy3kvHneYLRXNjdkve71HU085TchiQQZBNOAzIlOtvj7+vqwma0wswfNbEaA5REZ1abUlqWfL545lrGVMSbXePv2NGf3E1zwL3/kqrvr6cm3HJqUnOG+ffTXwEzn3AnAEuDufCeZ2dVmVm9m9bt37y5oAUVGgkjIsmoHKbXlUaJhY3dLJ4lkD7uaO3Cu94//W3taCllMKVJB3jW0Fcj8hj/d35fmnNubsflj4Hv53sg5dwdwB8DixYv1FUYkwx///iwq4/n/KYdCxrjKOI+t3M59L73N/rYuLl00PX186ab9HDWxulBFlSIVZI3gZWC2mc0ysxhwOfBI5glmNiVj8wPAawGWR2RUmjG2grH+Wsf5TKiOs2lvGzXlUc6aM4EHl25JH/vSQytZt7M5vb2toZ2bHl6VXg1NSkNgQeCcSwLXAk/g/YH/hXNutZl9w8w+4J/2f81stZm9Cvxf4C+DKo9IqSqLev/ML1s0nVuvOJG5k6u5+owj+PePLwTgxQ370udef/9y7vnTJpb36VyW0S3QAWXOuceAx/rsuynj+Q3ADUGWQaTUbWvoAGD+jDpqyqL89vozAG+G0uqyCGt39I4zWO1PaPfLZVuYNqacaXXluW8oo85wdxaLSMBS01WfMK0ua7+ZMXdyNa9v95qG2hPdtPpTVdz38mZufXJdYQsqw0ZTTIiMcrd9bCGvbW+itiKac2zO5GoeXr4N5xxrtjdmHVu6aX+hiijDTEEgMsqNr4rzntkT8h6bM7mG5lJKek4AAA1qSURBVI63uXnJOiKh7AaCN3e30tCWoK6i/45oGR0UBCIlbO5k79bRf/v9egAmVsfZlTH47JW3Gzhr7sRhKZsUjvoIRErY0ZOyxxCcf+wkvvOh4/n4uw8jHDI1D5UI1QhESlhteW+/wbVnHcW1Zx9FWTTM5cCKLY0KghKhGoFIiXv0c6fzzBfP5Avvm5Ne5wDg1KPG8cKGvTxQv5lkdw93PreBbQ3tAGzc08rz6/cMV5FliFnmvCMjweLFi119ff1wF0Nk1Ovo6uajP/oTr21v5t1HjOWPb+xh7uRq5k+v4/56bz7J9d+6kEhY3ydHAjNb6pxbnO+Y/g+KSF5l0TAfXjSdRHcPf3xjDxOr47y+ozkdAgCv7+idnuJv71/O1ffoS9pIpCAQkX5ddPwUFsyo4/6rT+bFG8/h4hOmMLYylh5xvOzt3j6EX72yld+t0RoHI5E6i0WkX+Or4vzPNaelt//tihNxDszg5H96iqWb9nPG7Akke3onqdvT0sn4qvhwFFcOkoJARAbNzEgte7Do8DEs3bSfM7//h6xz7n95MzPGVnD+vElZnc9SvBQEInJQFh42hsdW7sjZ/89PrE0///W1p1MeC3HE+CpCodyFc6Q4qI9ARA7KqUeOz9p+z+zxzOkzQO2bv1nDuTc/yy/qNyPFSzUCETko86bWcPenTmLr/naOmljFCdNr2dPSyY//uIEvXTCXC259Nr3WwfLNDSyeOYbpYyp4dMV2fvL8Bm772EJmja8c5k8hoHEEIhKQK+96iWfXeWuMT60tY1tjR9bxDy2cxs0fWZDzutbOJG2JbiZUq8N5KGkcgYgU3NfeP4+bPzKfT58+KysErjzlcC5dNJ1HX91Oc0dXzus++dOXede3niTZreUyC0VNQyISiCMmVHHEhCrmTG7kx89tAODmj8znkgXTeOXt/Ty4dAvHf+13fGjhNOKREDPHVfLT/93Idj80nn9zL+89Ov/02TK0FAQiEqhjp9Zy6+ULiEdCXHDcFMC742hcZYy9rQl+uWxr3tf97E+b3nEQtCWSlEXCukPpHVLTkIgE7pIF09IhABAKGU99/r2c7a918NX3z6MqHqE8GuaGC+dy3TmzefK1nfzXC5t47o09NHd00dTRxd/dv5wP3v48W/3J7zJ1dHUz76Yn+O4Trxfsc40W6iwWkWHT0plkw+5Wjp9eS0tnku4eR215lPZEN1fe9SIvb8w/DXY0bNz2sYXMHFfJmu2NbGvoYExFjBt/tRKAjd/5P4X8GCPCQJ3FCgIRKUqJZA+/f30Xe1s7eXj5NgD+7MRpnDRrLNfft5yVWxv7fe1nzziCGy46Jmf//tYE1/x8GR9aOJ1LF00PrOzFSEEgIqPKs+t2c+VdL+XsD4eM7h7vb9oT15/BlLoyfvLcRo6cWMkD9Vt4xr+ddfbEKpb83XtzXv/Shn3EIyHmz6gL9gMMg4GCQJ3FIjLinHLkOAAm1cTZ2eStsfyNS47lgydO457/3cj3f7eOS25/jo6u3FtQzz1mEk++tpP7X36bk48Yx8PLt9HjHP/1wtvsafHe68dXLubceZN45NVtVETDnDtvEgA7GjvY09LJcdNqc9432d3Dp++p54MLpvHBE6flHF/29n6OHF9FbUU059hwU41AREakN3e3UFseZfO+NqLhUNYf5yVrdvLN36xhy/52/46lMMdPq6W6LEKPc1z103pe2rgv6/0O8yfKe3zVDva3JaiIhdnTkgDg2Kk1RELGq1u85qi137yAeMSbUC/Z3YOZ8eDSzXzpoZXEIiHWffPCrPfevK+NM7//B86ZO5E7rsz7pTxwahoSkZLTlkiyq6mTmXmmsejo6uYvf/ISq7c2cdP753HMlBqOmVJDOGSs2trIPz66hqWb9pPs6f37GAlZenvelBpaOpNEwsaW/e0kktk1j3+4eB6/W72Da88+ipnjKvnre5eyamsTAL/47ClMqI5z+NgKOpLdvPDWXsoiYbbsb6elM8mnTp+V9Rmu/fkrfPr0WSyaOYaubkdV/OAachQEIiLvUHePo6m9i13NnTy6YhsfXjid36zczi1L1qUDIR4J0ZnsIWRw+UmHcdqR47nm58vS7xEyqIxFSPY4PnfOUdzzv5vY0eQNmDt+Wi0b9rTS0pnM+rn/eeViNuxp4fn1e9N9GimfO/soPn/+nIP6PAoCEZEhsmFPKw1tCZo7kpx21Hga2hKM8xficc7x0oZ9NHUkmVgd567nN7Blfzs3XnQMiw4fw/Pr93DLknWEQsZbu1uZVBPnC++bw76WBNsa2vnBknXpnzO2MkY0bDS1ezWPy981g/OPncy7Zo49qHIPWxCY2QXArUAY+LFz7jt9jseBe4BFwF7go865jQO9p4JAREaDhF+TiIR7x/Xe99LbdHR1c+HxUxhfFSfsj5B2zmF2aKOlh+WuITMLA7cD5wFbgJfN7BHn3JqM064C9jvnjjKzy4HvAh8NqkwiIsUiFsmd2OHykw7Le+6hhsCBBDnFxEnAeufcW865BHAfcEmfcy4B7vafPwicY0F/YhERyRLkOIJpQOayRFuAd/d3jnMuaWaNwDhgT+ZJZnY1cLW/2WJmazk44/u+twC6Lv3Rdcmla5LfSLguh/d3YEQMKHPO3QHccajvY2b1/bWRlTJdl/x0XXLpmuQ30q9LkE1DW4EZGdvT/X15zzGzCFCL12ksIiIFEmQQvAzMNrNZZhYDLgce6XPOI8An/OeXAr93I+1+VhGRES6wpiG/zf9a4Am820fvcs6tNrNvAPXOuUeAO4Gfmdl6YB9eWATpkJuXRildl/x0XXLpmuQ3oq/LiBtQJiIiQ0srlImIlDgFgYhIiSuZIDCzC8xsrZmtN7MvD3d5CsnM7jKzXWa2KmPfWDNbYmZv+P8d4+83M/tX/zqtMLOFw1fy4JjZDDN72szWmNlqM7vO31/q16XMzF4ys1f96/J1f/8sM3vR//z3+zeAYGZxf3u9f3zmcJY/SGYWNrNXzOxRf3vUXJOSCIKM6S4uBOYBV5jZvOEtVUH9FLigz74vA08552YDT/nb4F2j2f7jauA/ClTGQksCn3fOzQNOBq7xfydK/bp0Amc75+YDC4ALzOxkvOlfbnHOHQXsx5seBjKmiQFu8c8bra4DXsvYHj3XxDk36h/AKcATGds3ADcMd7kKfA1mAqsyttcCU/znU4C1/vMfAVfkO280P4CH8ebF0nXp/YwVwDK8GQH2ABF/f/rfE95dgaf4zyP+eTbcZQ/gWkzH+2JwNvAoYKPpmpREjYD8013kriVXWiY557b7z3cAk/znJXet/Kr7icCL6LqkmkCWA7uAJcCbQINzLjVxfuZnz5omBkhNEzPa/Avw90BqBZpxjKJrUipBIANw3leXkryP2MyqgIeA651zTZnHSvW6OOe6nXML8L4FnwTMHeYiDSszuxjY5ZxbOtxlCUqpBMFgprsoNTvNbAqA/99d/v6SuVZmFsULgXudc7/0d5f8dUlxzjUAT+M1e9T508BA9mcvhWliTgM+YGYb8WZRPhtvnZVRc01KJQgGM91Fqcmc3uMTeG3kqf1X+nfJnAw0ZjSVjBr+dOd3Aq85527OOFTq12WCmdX5z8vx+k1ewwuES/3T+l6XUT1NjHPuBufcdOfcTLy/Hb93zn2c0XRNhruTooCdPRcB6/DaO78y3OUp8Gf/b2A70IXXlnkVXpvlU8AbwJPAWP9cw7vD6k1gJbB4uMsf0DU5Ha/ZZwWw3H9cpOvCCcAr/nVZBdzk7z8CeAlYDzwAxP39Zf72ev/4EcP9GQK+PmcCj462a6IpJkRESlypNA2JiEg/FAQiIiVOQSAiUuIUBCIiJU5BICJS4hQEUtLMrNvMlvuzbS4zs1MPcH6dmf3NIN73D2Y26MXMzey//XEu15vZFYN9nchQUBBIqWt3zi1w3mybNwD/dIDz64ADBsFBmOmc2wC8F3g2gPcX6ZeCQKRXDd50wphZlZk95dcSVprZJf453wGO9GsR/+yf+yX/nFfN7DsZ73eZP7f/OjN7T74faGb3mtkaYK4/0dv5wG/M7NOBfUqRPgJbvF5khCj3/wCX4U07fba/vwP4M+dck5mNB14ws0fw1ic4znmTsmFmFwKXAO92zrWZ2diM9444504ys4uArwLn9v3hzrmPm9llwGHAg8D3nXOXBfNRRfJTEEipa8/4o34KcI+ZHYc3pcS3zewMvKmHp9E7JXWmc4GfOOfaAJxz+zKOpSayW4q3HkR/FuJNa3EC8OrBfxSRg6MgEPE55/7kf/ufgDfv0ARgkXOuy595suwdvmWn/99u8vxb82sK3wZmARf7P6/VzM5xzp11cJ9C5J1TH4GIz8zmAmG8KYNr8eag7zKzs4DD/dOageqMly0BPmlmFf57ZDYNDcg59xiwCG/luOOB1cCJCgEpNNUIpNSl+gjAaw76hHOu28zuBX5tZiuBeuB1AOfcXjN73sxWAY87575oZguAejNLAI8BN76Dn38i8Ko/PXrU9VkcR6QQNPuoiEiJU9OQiEiJUxCIiJQ4BYGISIlTEIiIlDgFgYhIiVMQiIiUOAWBiEiJ+/9IY44xB4+PeAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))"
      ],
      "metadata": {
        "id": "qvV5dfZhfuC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9huBvZvfxH1",
        "outputId": "7ac88313-8c26-44db-e9fe-eb46392405ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_text(self, result_tokens):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "  shape_checker(result_text, ('batch'))\n",
        "\n",
        "  result_text = tf.strings.strip(result_text)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "  return result_text"
      ],
      "metadata": {
        "id": "Gq8L4S6uf0g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Translator.tokens_to_text = tokens_to_text"
      ],
      "metadata": {
        "id": "aky-p94gf3qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_output_tokens = tf.random.uniform(\n",
        "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
        "    maxval=output_text_processor.vocabulary_size())\n",
        "translator.tokens_to_text(example_output_tokens).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyVeWiv4f8SE",
        "outputId": "6dd6fef5-31fb-4a66-f232-ddf54e9d8c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'(1h)NOW+AFTERNOON_2 SISTER', b'REQUEST READ+',\n",
              "       b'(2h)LOOK (2h)alt.EAT+', b'missing LETTER/MAIL', b'GRASS MOVIE_2'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(self, logits, temperature):\n",
        "  shape_checker = ShapeChecker()\n",
        "  # 't' is usually 1 here.\n",
        "  shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "  shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  if temperature == 0.0:\n",
        "    new_tokens = tf.argmax(logits, axis=-1)\n",
        "  else: \n",
        "    logits = tf.squeeze(logits, axis=1)\n",
        "    new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "  \n",
        "  shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "  return new_tokens"
      ],
      "metadata": {
        "id": "LPxssDgFgBZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Translator.sample = sample"
      ],
      "metadata": {
        "id": "3Dqq3Tm7gIQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n",
        "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
        "example_output_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQyyJfNDgKz9",
        "outputId": "0728bae8-1fd1-48b9-8c37-a15fa89ed858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
              "array([[1159],\n",
              "       [ 217],\n",
              "       [ 890],\n",
              "       [1087],\n",
              "       [1108]])>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "    \n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    attention.append(dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "\n",
        "    result_tokens.append(new_tokens)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}\n"
      ],
      "metadata": {
        "id": "hqdZonoggPci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Translator.translate = translate_unrolled"
      ],
      "metadata": {
        "id": "Pfxvae8wgS_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = \"sentencesTest.txt\"\n",
        "out_file = \"output.txt\"\n",
        "out = open(out_file, \"w\")\n",
        "\n",
        "with open(test_file,encoding=\"unicode_escape\" ) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "for s in lines:\n",
        "    data_lst = []\n",
        "    data_lst.append(s)\n",
        "    txt = tf.constant(data_lst)\n",
        "    result = translator.translate(txt = txt)\n",
        "    translated = result['text'][0].numpy().decode()\n",
        "    translated = translated.replace(\" \", \",\")   \n",
        "    out.write(translated+'\\n')\n",
        "\n",
        "out.close()"
      ],
      "metadata": {
        "id": "M4RcoHAgczzF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}